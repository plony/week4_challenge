{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logging Setup\n",
    "logging.basicConfig(filename='store_sales_analysis.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info('Loading the dataset...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Data\n",
    "store_data = pd.read_csv('store.csv')\n",
    "train_data = pd.read_csv('train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Cleaning\n",
    "logging.info('Handling missing data...')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = store_data.isnull().sum()\n",
    "logging.info(f\"Missing values in dataset:\\n{missing_values}\")\n",
    "\n",
    "# Handling missing values - Example for 'CompetitionDistance'\n",
    "store_data['CompetitionDistance'].fillna(store_data['CompetitionDistance'].median(), inplace=True)\n",
    "\n",
    "# Handling missing values for competition open dates\n",
    "store_data['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\n",
    "store_data['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n",
    "\n",
    "# Handling Promo2 columns\n",
    "store_data['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "store_data['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "store_data['PromoInterval'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Merge store and sales data (assuming they share a common column)\n",
    "merged_data = pd.merge(train_data_data, store_data, on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check for outliers in sales\n",
    "logging.info('Checking for outliers in sales data...')\n",
    "sns.boxplot(x=merged_data['Sales'])\n",
    "plt.title('Outliers in Sales')\n",
    "plt.show()\n",
    "\n",
    "# Handling outliers: Remove sales = 0 (if needed)\n",
    "merged_data = merged_data[merged_data['Sales'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Check for distribution in promotions\n",
    "logging.info('Checking promotion distribution between training and test sets...')\n",
    "sns.countplot(x='Promo', data=merged_data)\n",
    "plt.title('Promo Distribution in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Sales behavior before, during, and after holidays\n",
    "logging.info('Analyzing sales behavior during holidays...')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='StateHoliday', y='Sales', data=merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Weekly Sales\n",
    "# Ensure the date column is in datetime format\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "\n",
    "# Extract the week from the date\n",
    "merged_data['Week'] = merged_data['Date'].dt.isocalendar().week\n",
    "\n",
    "# Group by week and calculate the total sales for each week\n",
    "weekly_sales = merged_data.groupby('Week')['Sales'].sum().reset_index()\n",
    "\n",
    "# Plot weekly sales\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=weekly_sales, x='Week', y='Sales')\n",
    "plt.title('Weekly Sales')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Monthly Sales\n",
    "# Extract the month from the date\n",
    "merged_data['Month'] = merged_data['Date'].dt.month\n",
    "\n",
    "# Group by month and calculate the total sales for each month\n",
    "monthly_sales = merged_data.groupby('Month')['Sales'].sum().reset_index()\n",
    "\n",
    "# Plot monthly sales\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=monthly_sales, x='Month', y='Sales')\n",
    "plt.title('Monthly Sales')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of Seasonal Decomposition:\n",
    "Trend: Shows the overall direction (upwards, downwards) over time.\n",
    "Seasonal: Recurring patterns (e.g., sales spikes during holiday seasons).\n",
    "Residual: The remainder after removing trend and seasonality, representing noise or random fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seasonal Decomposition\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Set the Date column as the index for time series analysis\n",
    "merged_data.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample the sales data by day to handle any missing dates\n",
    "daily_sales = merged_data['Sales'].resample('D').sum()\n",
    "\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(daily_sales, model='additive', period=365)  # period = 365 for yearly seasonality\n",
    "\n",
    "# Plot the decomposition\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights from the Plots:\n",
    "ACF: Helps to identify the presence of significant correlations at specific lag values. A high autocorrelation at a particular lag indicates that previous values at that lag are influencing current values.\n",
    "PACF: Isolates the direct relationship between the time series and its lag, without considering the influence of intermediate lags.\n",
    "These plots are essential for determining the optimal number of lags (p, d, q) when building models like ARIMA or other time-series models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Load the dataset (assuming you've already loaded the 'store.csv' file)\n",
    "df = pd.read_csv('/mnt/data/store.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime if not already done\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set 'Date' as index for time series analysis\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample the data to daily sales (this assumes 'Sales' column exists in your dataset)\n",
    "daily_sales = df['Sales'].resample('D').sum()\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot roling statistcis \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/mnt/data/store.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set 'Date' as the index for time series analysis\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensure 'Sales' column is numeric\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "\n",
    "# Choose a window size (e.g., 7 days for weekly, 30 for monthly)\n",
    "window_size = 30\n",
    "\n",
    "# Calculate rolling mean and standard deviation\n",
    "rolling_mean = df['Sales'].rolling(window=window_size).mean()\n",
    "rolling_std = df['Sales'].rolling(window=window_size).std()\n",
    "\n",
    "# Plot the rolling statistics\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['Sales'], color='blue', label='Original Sales')\n",
    "plt.plot(rolling_mean, color='red', label=f'{window_size}-day Rolling Mean')\n",
    "plt.plot(rolling_std, color='black', label=f'{window_size}-day Rolling Std')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Rolling Mean & Standard Deviation (Window Size = {window_size})')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12-Month Rolling Mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/mnt/data/store.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set 'Date' as the index for time series analysis\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensure 'Sales' column is numeric\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "\n",
    "# Choose a window size for 12 months (approximately 12 * 30 days = 360 days)\n",
    "window_size = 360  # 12 months of daily data\n",
    "\n",
    "# Calculate rolling mean\n",
    "rolling_mean_12m = df['Sales'].rolling(window=window_size).mean()\n",
    "\n",
    "# Plot the original sales and 12-month rolling mean\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['Sales'], color='blue', label='Original Sales')\n",
    "plt.plot(rolling_mean_12m, color='red', label='12-Month Rolling Mean')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('12-Month Rolling Mean of Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preparation\n",
    "# Assuming 'Date' is a string, convert it to datetime\n",
    "sales_data['Date'] = pd.to_datetime(sales_data['Date'])\n",
    "\n",
    "# 2. 12-Month Rolling Standard Deviation\n",
    "sales_data['12M_Rolling_Std'] = sales_data['Sales'].rolling(window=12).std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Average Sales by Day of the Week\n",
    "sales_data['Day_of_Week'] = sales_data['Date'].dt.day_name()\n",
    "avg_sales_by_day = sales_data.groupby('Day_of_Week')['Sales'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Holiday Column\n",
    "sales_data['Holiday'] = sales_data['Date'].isin(holiday_dates)  # Replace holiday_dates with actual holiday dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sales Distribution: Holiday vs. Non-Holiday\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(sales_data['Sales'], hue=sales_data['Holiday'])\n",
    "plt.title('Sales Distribution by Holiday')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Summary Statistics\n",
    "print(sales_data[['Sales', 'Customers']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Holiday Effect\n",
    "holiday_sales = sales_data[sales_data['Holiday'] == True]['Sales']\n",
    "non_holiday_sales = sales_data[sales_data['Holiday'] == False]['Sales']\n",
    "t_stat, p_value = ttest_ind(holiday_sales, non_holiday_sales)\n",
    "print('T-statistic:', t_stat, 'P-value:', p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Promo Effect Over Time\n",
    "\n",
    "# Assuming 'Promotion' is a binary indicator\n",
    "promo_sales = sales_data[sales_data['Promotion'] == 1]['Sales']\n",
    "non_promo_sales = sales_data[sales_data['Promotion'] == 0]['Sales']\n",
    "\n",
    "t_stat_promo, p_value_promo = ttest_ind(promo_sales, non_promo_sales)\n",
    "print('Promo Effect T-statistic:', t_stat_promo, 'P-value:', p_value_promo)\n",
    "\n",
    "# Visualize the effect over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Date', y='Sales', hue='Promotion', data=sales_data)\n",
    "plt.title('Sales Over Time by Promotion')\n",
    "plt.show()\n",
    "# 9. Store Type Performance Over Time\n",
    "if 'Store_Type' in sales_data.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='Date', y='Sales', hue='Store_Type', data=sales_data)\n",
    "    plt.title('Sales Over Time by Store Type')\n",
    "    plt.show()\n",
    "# 10. Sales vs. Customers Scatter Plot\n",
    "plt.scatter(sales_data['Customers'], sales_data['Sales'])\n",
    "plt.xlabel('Customers')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Sales vs. Customers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 11. Cumulative Sales Over Time\n",
    "sales_data['Cumulative_Sales'] = sales_data['Sales'].cumsum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Daily Sales Growth Rate\n",
    "sales_data['Daily_Growth_Rate'] = sales_data['Sales'].pct_change()\n",
    "\n",
    "# 13. Data Cleaning and Correlation Analysis\n",
    "# sales_data['Sales'] = sales_data['Sales'].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_matrix = sales_data[['Sales', 'Customers', 'Promotion', 'Holiday']].corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize correlations\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
