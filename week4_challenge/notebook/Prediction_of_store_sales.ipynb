{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction:\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "df['is_beginning_of_month'] = df['Date'].dt.day <= 7\n",
    "df['is_mid_month'] = df['Date'].dt.day.between(8, 14)\n",
    "df['is_end_of_month'] = df['Date'].dt.day > 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = ['DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "             'is_beginning_of_month', 'is_mid_month', 'is_end_of_month']\n",
    "df[features] = scaler.fit_transform(df[features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models with sklearn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pipelines\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "             'is_beginning_of_month', 'is_mid_month', 'is_end_of_month'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Model\n",
    "X = df.drop(['Id', 'Date'], axis=1)  # Exclude non-feature columns\n",
    "y = df['Sales']  # Assuming you have a 'Sales' column in your full dataset\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "importances = model.named_steps['regressor'].feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "print(importance_df.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confidence Intervals useing bootstrapping to estimate confidence intervals for predictions\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_predictions(model, X, y, n_iterations=1000):\n",
    "    predictions = []\n",
    "    for _ in range(n_iterations):\n",
    "        indices = np.random.choice(len(X), len(X), replace=True)\n",
    "        X_boot = X.iloc[indices]\n",
    "        y_boot = y.iloc[indices]\n",
    "        model.fit(X_boot, y_boot)\n",
    "        preds = model.predict(X)\n",
    "        predictions.append(preds)\n",
    "    predictions = np.array(predictions)\n",
    "    return np.percentile(predictions, [2.5, 97.5], axis=0)  # 95% CI\n",
    "\n",
    "ci = bootstrap_predictions(model, X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Serialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%d-%m-%Y-%H-%M-%S-%f')\n",
    "joblib.dump(model, f'model_{timestamp}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Model with Deep Learning\n",
    "#Prepare Data for LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled_data = scaler.fit_transform(df[['Sales']])  # Assuming 'Sales' is the target\n",
    "\n",
    "generator = TimeseriesGenerator(scaled_data, scaled_data, length=14, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build LSTM Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(14, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate & Predict\n",
    "predictions = model.predict(generator)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
